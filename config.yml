# Config file for Hadoop data. Download it from:
# https://zenodo.org/records/8196385/files/Hadoop.zip?download=1 

# Specify input data and output folders
input_data_folder: "/home/mmantyla/Datasets/hadoop"
output_folder: "/home/mmantyla/output/hadoop"

#Any dataset specific preprocessing can be done here. 
preprocessing_steps:
  - name: "remove_run_name_from_file_names"

# Do you want to mask, e.g., 192.168.1.1 -> <IP>?
# If unsure, the answer is YES.
# Modify masks in regex_masking.py
regex_masking:
  enabled: true
  pattern:
    - name: "myllari_extended" #Only one name currently supported. 

# Do you want to pre-parse? This only works if regex_masking is enabled.
# Set "enabled: true" only if your steps utilize options like Parse-Tip or Parse-Drain.
# Otherwise, set it to false.
# If pre-parsing is not enabled and you utilize, for example, Parse-Tip, 
# the parse call may occur multiple times on subsets of data, which could impact performance.
pre_parse:
  enabled: true
  parsers: 
    - name: "Parse-Tip" #Other valid parse options are Parse-Drain, Parse-Brain and everything that is listed as parse_*() in https://github.com/EvoTestOps/LogLead/blob/main/loglead/enhancers/eventlog.py
    #- name: "Parse-Drain"

#Note: CSV writer cannot handel nested columns so they get dropped
table_output: "xlsx" #Valid options xlsx and csv.


steps:
  # Similarity based comparisons
  # Level 1
  distance_run_file:
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
   
  # Level 2
  distance_run_content:
    - target_run: "application_1445062781478_0011"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: False #TODO rename this to mask_content
      content_format: "Sklearn" #Words and 3grams require loglead 1.1.1
      vectorizer: "Count"
    - target_run: "application_1445062781478_0011"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: True #TODO rename this to mask_content
      content_format: "Sklearn"
      vectorizer: "Count"
    - target_run: "application_1445062781478_0011"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: True #TODO rename this to mask_content
      content_format: "Parse-Tip"
      vectorizer: "Count"




  # #Level 3
  distance_file_content:
    - target_run: "application_1445062781478_0011"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: True
      content_format: "Sklearn" #3grams and Words require loglead 1.1.1
      vectorizer: "Count"
    - target_run: "application_1445062781478_0011"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: True
      content_format: "Parse-Drain"
      vectorizer: "Count"
  #Level 4. This runs diff algo. We could also implement it with e.g. relaxed word mover distance or similar string distance. Not sure if it make
  distance_line_content:
    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs:
        - "application_1445062781478_0012"
        - "application_1445062781478_0013"
        - "application_1445062781478_0014"
      normalize_content: True

  # Anomaly detection based models
  # Level 1
  anomaly_run_file: 
    - target_run: 3 #for anomaly_run_file we can also specify a number for target_run
      comparison_runs: 10
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
 #Level 2
  anomaly_run_content:
    - target_run: 3
      comparison_runs: 10 #for anomaly_run_file we can also specify a number for target_run
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Parse-Tip" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf
    - target_run: 3
      comparison_runs: 10 #for anomaly_run_file we can also specify a number for target_run
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "3grams" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Tfidf" #Valid options: Count Tfidf
    - target_run: 3
      comparison_runs: 10 #for anomaly_run_file we can also specify a number for target_run
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Sklearn" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf
    - target_run: 3
      comparison_runs: 10 #for anomaly_run_file we can also specify a number for target_run
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Words" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf



  # Level 3
  anomaly_file_content:
    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs: 10
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Words" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf

    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs: 10
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "3grams" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Tfidf" #Valid options: Count Tfidf

    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs: 10
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Parse-Tip" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf

    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs: 10
      normalize_content: True
      detectors:
        - IsolationForest
        - KMeans
        - RarityModel
        - OOVDetector
      content_format: "Sklearn" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf


  # Level 4 - includes plotting
  anomaly_line_content:
    - target_run: "application_1445062781478_0011"
      target_files:
      - "container__01_000001.log"
      - "container__01_000002.log"
      - "container__01_000003.log"
      comparison_runs: "ALL"
      normalize_content: True
      detectors:
       - IsolationForest
       - KMeans
       - RarityModel
       - OOVDetector
      content_format: "Words" #Valid options: 3grams, Sklearn, Parse
      vectorizer: "Count" #Valid options: Count Tfidf
  #Plotting. 
  # #Level 1
  plot_run_file:
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      group_by_indices: [0, 1] #use first and second element WordCount and DiskFull

  #Level 1
  plot_run_content:
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      group_by_indices: [0, 1] 
      normalize_content: True
      content_format: "3grams"
      vectorizer: "Tfidf"
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      group_by_indices: [0, 1] 
      normalize_content: True
      content_format: "Words"
      vectorizer: "Count"
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      group_by_indices: [0, 1] 
      normalize_content: True
      content_format: "Parse-Tip" #Other valid parse options are Parse-Drain, Parse-Brain and everything that is listed as parse_*() in https://github.com/EvoTestOps/LogLead/blob/main/loglead/enhancers/eventlog.py
      vectorizer: "Count"
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      group_by_indices: [0, 1] 
      normalize_content: True
      content_format: "Sklearn"
      vectorizer: "Tfidf"
    
  #Level 3 - Same options as Level 2 plotting for vectorizer and content_format
  plot_file_content:
    - target_run: "application_1445062781478_0011"
      comparison_runs: "ALL"
      target_files:
      - "container__01_000001.log"
      group_by_indices: [0, 1]
      normalize_content: True
      content_format: "Words"
      vectorizer: "Tfidf"



